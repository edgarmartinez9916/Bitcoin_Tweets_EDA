{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796d0acd",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to start by loading in the dataset and cleaning it to make sure all columns are the correct datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2bcf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8521d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edgar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (4,5,6,7,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"Data/Raw_Bitcoin_tweets.csv\") #Loads in csv file to a pandas DataFrame\n",
    "\n",
    "# load data\n",
    "# We see that we might have formatting issues with the user_created, \n",
    "# user_followers, user_friends, user_favourites, and is_retweet columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdf03a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeSota Wilson</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Biz Consultant, real estate, fintech, startups...</td>\n",
       "      <td>2009-04-26 20:05:09</td>\n",
       "      <td>8534.0</td>\n",
       "      <td>7605</td>\n",
       "      <td>4838</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-02-10 23:59:04</td>\n",
       "      <td>Blue Ridge Bank shares halted by NYSE after #b...</td>\n",
       "      <td>['bitcoin']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CryptoND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ðŸ˜Ž BITCOINLIVE is a Dutch platform aimed at inf...</td>\n",
       "      <td>2019-10-17 20:12:10</td>\n",
       "      <td>6769.0</td>\n",
       "      <td>1532</td>\n",
       "      <td>25483</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-02-10 23:58:48</td>\n",
       "      <td>ðŸ˜Ž Today, that's this #Thursday, we will do a \"...</td>\n",
       "      <td>['Thursday', 'Btc', 'wallet', 'security']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tdlmatias</td>\n",
       "      <td>London, England</td>\n",
       "      <td>IM Academy : The best #forex, #SelfEducation, ...</td>\n",
       "      <td>2014-11-10 10:50:37</td>\n",
       "      <td>128.0</td>\n",
       "      <td>332</td>\n",
       "      <td>924</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-02-10 23:54:48</td>\n",
       "      <td>Guys evening, I have read this article about B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crypto is the future</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I will post a lot of buying signals for BTC tr...</td>\n",
       "      <td>2019-09-28 16:48:12</td>\n",
       "      <td>625.0</td>\n",
       "      <td>129</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-02-10 23:54:33</td>\n",
       "      <td>$BTC A big chance in a billion! Price: \\487264...</td>\n",
       "      <td>['Bitcoin', 'FX', 'BTC', 'crypto']</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex Kirchmaier ðŸ‡¦ðŸ‡¹ðŸ‡¸ðŸ‡ª #FactsSuperspreader</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Co-founder @RENJERJerky | Forbes 30Under30 | I...</td>\n",
       "      <td>2016-02-03 13:15:55</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>1472</td>\n",
       "      <td>10482</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-02-10 23:54:06</td>\n",
       "      <td>This network is secured by 9 508 nodes as of t...</td>\n",
       "      <td>['BTC']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  user_name    user_location  \\\n",
       "0                             DeSota Wilson      Atlanta, GA   \n",
       "1                                  CryptoND              NaN   \n",
       "2                                 Tdlmatias  London, England   \n",
       "3                      Crypto is the future              NaN   \n",
       "4  Alex Kirchmaier ðŸ‡¦ðŸ‡¹ðŸ‡¸ðŸ‡ª #FactsSuperspreader           Europa   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Biz Consultant, real estate, fintech, startups...  2009-04-26 20:05:09   \n",
       "1  ðŸ˜Ž BITCOINLIVE is a Dutch platform aimed at inf...  2019-10-17 20:12:10   \n",
       "2  IM Academy : The best #forex, #SelfEducation, ...  2014-11-10 10:50:37   \n",
       "3  I will post a lot of buying signals for BTC tr...  2019-09-28 16:48:12   \n",
       "4  Co-founder @RENJERJerky | Forbes 30Under30 | I...  2016-02-03 13:15:55   \n",
       "\n",
       "  user_followers user_friends user_favourites user_verified  \\\n",
       "0         8534.0         7605            4838         False   \n",
       "1         6769.0         1532           25483         False   \n",
       "2          128.0          332             924         False   \n",
       "3          625.0          129              14         False   \n",
       "4         1249.0         1472           10482         False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2021-02-10 23:59:04  Blue Ridge Bank shares halted by NYSE after #b...   \n",
       "1  2021-02-10 23:58:48  ðŸ˜Ž Today, that's this #Thursday, we will do a \"...   \n",
       "2  2021-02-10 23:54:48  Guys evening, I have read this article about B...   \n",
       "3  2021-02-10 23:54:33  $BTC A big chance in a billion! Price: \\487264...   \n",
       "4  2021-02-10 23:54:06  This network is secured by 9 508 nodes as of t...   \n",
       "\n",
       "                                    hashtags               source is_retweet  \n",
       "0                                ['bitcoin']      Twitter Web App      False  \n",
       "1  ['Thursday', 'Btc', 'wallet', 'security']  Twitter for Android      False  \n",
       "2                                        NaN      Twitter Web App      False  \n",
       "3         ['Bitcoin', 'FX', 'BTC', 'crypto']              dlvr.it      False  \n",
       "4                                    ['BTC']      Twitter Web App      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()\n",
    "\n",
    "#Print first 5 rows to investigate the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9096b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3029118 entries, 0 to 3029117\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Dtype \n",
      "---  ------            ----- \n",
      " 0   user_name         object\n",
      " 1   user_location     object\n",
      " 2   user_description  object\n",
      " 3   user_created      object\n",
      " 4   user_followers    object\n",
      " 5   user_friends      object\n",
      " 6   user_favourites   object\n",
      " 7   user_verified     object\n",
      " 8   date              object\n",
      " 9   text              object\n",
      " 10  hashtags          object\n",
      " 11  source            object\n",
      " 12  is_retweet        object\n",
      "dtypes: object(13)\n",
      "memory usage: 300.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info() #Prints DataFrame info\n",
    "\n",
    "#We see that we have 3,029,118 rows and 13 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ec89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.drop(columns = [\"hashtags\", \"is_retweet\"]) #Drops the columns hashtags, and is_retweet\n",
    "\n",
    "#We are going to drop these columns because they are irrelavant for our EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9934acf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_name                31\n",
       "user_location       1506765\n",
       "user_description     376660\n",
       "user_created             83\n",
       "user_followers          124\n",
       "user_friends            124\n",
       "user_favourites         124\n",
       "user_verified           124\n",
       "date                    124\n",
       "text                    124\n",
       "source                 3738\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #Check to see nulls present in each column\n",
    "\n",
    "#We see that we have a large amount of nulls in user_location and user_description. This is fine since users are not\n",
    "#required to add their location or a description. What is not okay is nulls in user_names or text. This is because\n",
    "#these are essential columns needed for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04cb8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [\"user_name\", \"text\"], inplace = True) #Drop rows that have nulls in user_names or text. \n",
    "\n",
    "#These are necessary for an EDA so we will just drop the rows with nulls in these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dee0f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_name                 0\n",
       "user_location       1506660\n",
       "user_description     376568\n",
       "user_created              0\n",
       "user_followers            0\n",
       "user_friends              0\n",
       "user_favourites           0\n",
       "user_verified             0\n",
       "date                      0\n",
       "text                      0\n",
       "source                 3614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #Check to see nulls present in each column\n",
    "\n",
    "#Verify that nulls were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78ae9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_name           object\n",
       "user_location       object\n",
       "user_description    object\n",
       "user_created        object\n",
       "user_followers      object\n",
       "user_friends        object\n",
       "user_favourites     object\n",
       "user_verified       object\n",
       "date                object\n",
       "text                object\n",
       "source              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes #Checks to see the data type in each column\n",
    "\n",
    "#Looks like columns 3,4,5,6,7, and 8 were imported incorrectly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52001712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64943</th>\n",
       "      <td>Can roam the worldï¼ŒIt's nine to five againáµ•á´—áµ•)...</td>\n",
       "      <td>2020-11-09 19:44:24</td>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-04-07 16:23:03</td>\n",
       "      <td>@krakenfx  #ETH #BTC  If you want to become po...</td>\n",
       "      <td>['ETH', 'BTC', 'Bitcoin']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137068</th>\n",
       "      <td>*Muhammad Yasir* hello stalker nice to tweet ...</td>\n",
       "      <td>2009-08-31 07:40:42</td>\n",
       "      <td>280.0</td>\n",
       "      <td>623</td>\n",
       "      <td>499.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-06-23 14:51:12</td>\n",
       "      <td>Official ESHOP Airdrop. If You Missed Meme Tok...</td>\n",
       "      <td>['cryptocurrency', 'BSC', 'Bitcoin', 'Ethereum...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180575</th>\n",
       "      <td>â€¢ Learn n To Do d'Best...!!!!!!!!</td>\n",
       "      <td>2010-08-16 10:55:09</td>\n",
       "      <td>52.0</td>\n",
       "      <td>277</td>\n",
       "      <td>127.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-06-22 13:31:16</td>\n",
       "      <td>@pufferswap Nice project\\n\\n@karnoto_hendrik \\...</td>\n",
       "      <td>['YieldFarming', 'Airdrop', 'Binance', 'Bitcoi...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693194</th>\n",
       "      <td>FB- Xiomara CastaÃ±eda</td>\n",
       "      <td>2015-12-21 18:17:12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>81</td>\n",
       "      <td>531.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-07-26 11:54:15</td>\n",
       "      <td>#btc to the moon ðŸš€ðŸš€ 77774</td>\n",
       "      <td>['btc']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697397</th>\n",
       "      <td>Pin bb : 26ea62f8 . Line : baliratih_bali</td>\n",
       "      <td>2012-06-01 01:08:25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-07-26 11:48:46</td>\n",
       "      <td>#btc to the moon ðŸš€ðŸš€ 46059</td>\n",
       "      <td>['btc']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067665</th>\n",
       "      <td>YOU'LL NEVER WALK ALONE</td>\n",
       "      <td>2012-08-29 10:32:29</td>\n",
       "      <td>71.0</td>\n",
       "      <td>314</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-08-16 16:39:27</td>\n",
       "      <td>@DogCakeFinance @DogCakeFinance Great project\\...</td>\n",
       "      <td>['YieldFarming', 'Airdrop', 'PancakeSwap', 'Gi...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347699</th>\n",
       "      <td>amp=l</td>\n",
       "      <td>2013-01-02 07:40:53</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-10-22 21:33:06</td>\n",
       "      <td>@bloodgoodBTC5\\n\\n#BitcoinÂ   \\n\\nShort term tr...</td>\n",
       "      <td>['Bitcoin']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393938</th>\n",
       "      <td>ðŸ’° based on the latest AI innovations</td>\n",
       "      <td>2021-03-31 11:02:58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-10-21 18:12:08</td>\n",
       "      <td>ðŸ¤¯Mind-blowing 99.7% of all Bitcoin holders are...</td>\n",
       "      <td>['cryptotrading', 'crypto', 'tradingbots', 'bi...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513850</th>\n",
       "      <td>My_Facebook http://t.co/tof8V41sTA</td>\n",
       "      <td>2012-08-24 20:37:55</td>\n",
       "      <td>285.0</td>\n",
       "      <td>933</td>\n",
       "      <td>389.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-10-29 08:22:59</td>\n",
       "      <td>@pythonwealth Good Project ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\\n\\n@nurull_pad...</td>\n",
       "      <td>['PW', 'pythonwealth', 'Presale', 'token', 'ic...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611481</th>\n",
       "      <td>https://t.co/atJqp3g7I2</td>\n",
       "      <td>2014-11-16 20:10:32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-11-06 04:05:58</td>\n",
       "      <td>@iftikharpost the world is flat #bitcoin ðŸ’ª</td>\n",
       "      <td>['bitcoin']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811149</th>\n",
       "      <td>jadii nine is 9 :D</td>\n",
       "      <td>2011-01-20 02:00:55</td>\n",
       "      <td>200.0</td>\n",
       "      <td>229</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-11-18 13:26:39</td>\n",
       "      <td>@airdropinspect Good and special project\\n@anc...</td>\n",
       "      <td>['Airdrop', 'Airdrops', 'Airdropinspector', 'B...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452878</th>\n",
       "      <td>I also love @monero and @nayibbukele</td>\n",
       "      <td>2022-02-22 17:50:16</td>\n",
       "      <td>26.0</td>\n",
       "      <td>274</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-03-18 21:43:15</td>\n",
       "      <td>DocumentingBTC: #bitcoin at $30: \"Am I too lat...</td>\n",
       "      <td>['bitcoin', 'bitcoin', 'bitcoin', 'bitcoin']</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599064</th>\n",
       "      <td>https://t.co/mzwhnIxibhâ€¦</td>\n",
       "      <td>2016-07-17 10:56:10</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-03-24 11:22:17</td>\n",
       "      <td>Crypto Market\\nOpen your Free Angel One Accoun...</td>\n",
       "      <td>['cryptocurrencies', 'bitcoin', 'cryptotrading...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612133</th>\n",
       "      <td>Electronics: Find tech deals for smartphones</td>\n",
       "      <td>watches</td>\n",
       "      <td>headphones</td>\n",
       "      <td>speakers</td>\n",
       "      <td>Laptops and more.\"</td>\n",
       "      <td>2021-10-09 06:21:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>Isn`t it awesome?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682674</th>\n",
       "      <td>:3. ...</td>\n",
       "      <td>2010-10-06 05:31:16</td>\n",
       "      <td>252.0</td>\n",
       "      <td>614</td>\n",
       "      <td>97.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-03-20 21:24:31</td>\n",
       "      <td>ðŸ’¸ Earn free #BTC and multiply crypto up to 15%...</td>\n",
       "      <td>['BTC', 'betfurysuccess']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 user_name  \\\n",
       "64943    Can roam the worldï¼ŒIt's nine to five againáµ•á´—áµ•)...   \n",
       "137068    *Muhammad Yasir* hello stalker nice to tweet ...   \n",
       "180575                   â€¢ Learn n To Do d'Best...!!!!!!!!   \n",
       "693194                               FB- Xiomara CastaÃ±eda   \n",
       "697397           Pin bb : 26ea62f8 . Line : baliratih_bali   \n",
       "1067665                            YOU'LL NEVER WALK ALONE   \n",
       "1347699                                              amp=l   \n",
       "1393938               ðŸ’° based on the latest AI innovations   \n",
       "1513850                 My_Facebook http://t.co/tof8V41sTA   \n",
       "1611481                            https://t.co/atJqp3g7I2   \n",
       "1811149                                 jadii nine is 9 :D   \n",
       "2452878               I also love @monero and @nayibbukele   \n",
       "2599064                           https://t.co/mzwhnIxibhâ€¦   \n",
       "2612133       Electronics: Find tech deals for smartphones   \n",
       "2682674                                            :3. ...   \n",
       "\n",
       "               user_location user_description user_created  \\\n",
       "64943    2020-11-09 19:44:24                9          141   \n",
       "137068   2009-08-31 07:40:42            280.0          623   \n",
       "180575   2010-08-16 10:55:09             52.0          277   \n",
       "693194   2015-12-21 18:17:12              9.0           81   \n",
       "697397   2012-06-01 01:08:25              4.0          110   \n",
       "1067665  2012-08-29 10:32:29             71.0          314   \n",
       "1347699  2013-01-02 07:40:53              9.0           33   \n",
       "1393938  2021-03-31 11:02:58              4.0           26   \n",
       "1513850  2012-08-24 20:37:55            285.0          933   \n",
       "1611481  2014-11-16 20:10:32              2.0           32   \n",
       "1811149  2011-01-20 02:00:55            200.0          229   \n",
       "2452878  2022-02-22 17:50:16             26.0          274   \n",
       "2599064  2016-07-17 10:56:10           1061.0           31   \n",
       "2612133              watches       headphones     speakers   \n",
       "2682674  2010-10-06 05:31:16            252.0          614   \n",
       "\n",
       "              user_followers         user_friends      user_favourites  \\\n",
       "64943                   36.0                False  2021-04-07 16:23:03   \n",
       "137068                 499.0                False  2021-06-23 14:51:12   \n",
       "180575                 127.0                False  2021-06-22 13:31:16   \n",
       "693194                 531.0                False  2021-07-26 11:54:15   \n",
       "697397                  21.0                False  2021-07-26 11:48:46   \n",
       "1067665               1968.0                False  2021-08-16 16:39:27   \n",
       "1347699                  0.0                False  2021-10-22 21:33:06   \n",
       "1393938                  0.0                False  2021-10-21 18:12:08   \n",
       "1513850                389.0                False  2021-10-29 08:22:59   \n",
       "1611481                 20.0                False  2021-11-06 04:05:58   \n",
       "1811149                 44.0                False  2021-11-18 13:26:39   \n",
       "2452878               2030.0                False  2022-03-18 21:43:15   \n",
       "2599064                  100                False  2022-03-24 11:22:17   \n",
       "2612133   Laptops and more.\"  2021-10-09 06:21:24                  1.0   \n",
       "2682674                 97.0                False  2022-03-20 21:24:31   \n",
       "\n",
       "                                             user_verified  \\\n",
       "64943    @krakenfx  #ETH #BTC  If you want to become po...   \n",
       "137068   Official ESHOP Airdrop. If You Missed Meme Tok...   \n",
       "180575   @pufferswap Nice project\\n\\n@karnoto_hendrik \\...   \n",
       "693194                           #btc to the moon ðŸš€ðŸš€ 77774   \n",
       "697397                           #btc to the moon ðŸš€ðŸš€ 46059   \n",
       "1067665  @DogCakeFinance @DogCakeFinance Great project\\...   \n",
       "1347699  @bloodgoodBTC5\\n\\n#BitcoinÂ   \\n\\nShort term tr...   \n",
       "1393938  ðŸ¤¯Mind-blowing 99.7% of all Bitcoin holders are...   \n",
       "1513850  @pythonwealth Good Project ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\\n\\n@nurull_pad...   \n",
       "1611481         @iftikharpost the world is flat #bitcoin ðŸ’ª   \n",
       "1811149  @airdropinspect Good and special project\\n@anc...   \n",
       "2452878  DocumentingBTC: #bitcoin at $30: \"Am I too lat...   \n",
       "2599064  Crypto Market\\nOpen your Free Angel One Accoun...   \n",
       "2612133                                                 35   \n",
       "2682674  ðŸ’¸ Earn free #BTC and multiply crypto up to 15%...   \n",
       "\n",
       "                                                      date  \\\n",
       "64943                            ['ETH', 'BTC', 'Bitcoin']   \n",
       "137068   ['cryptocurrency', 'BSC', 'Bitcoin', 'Ethereum...   \n",
       "180575   ['YieldFarming', 'Airdrop', 'Binance', 'Bitcoi...   \n",
       "693194                                             ['btc']   \n",
       "697397                                             ['btc']   \n",
       "1067665  ['YieldFarming', 'Airdrop', 'PancakeSwap', 'Gi...   \n",
       "1347699                                        ['Bitcoin']   \n",
       "1393938  ['cryptotrading', 'crypto', 'tradingbots', 'bi...   \n",
       "1513850  ['PW', 'pythonwealth', 'Presale', 'token', 'ic...   \n",
       "1611481                                        ['bitcoin']   \n",
       "1811149  ['Airdrop', 'Airdrops', 'Airdropinspector', 'B...   \n",
       "2452878       ['bitcoin', 'bitcoin', 'bitcoin', 'bitcoin']   \n",
       "2599064  ['cryptocurrencies', 'bitcoin', 'cryptotrading...   \n",
       "2612133                                                 20   \n",
       "2682674                          ['BTC', 'betfurysuccess']   \n",
       "\n",
       "                        text              source  \n",
       "64943        Twitter Web App                 NaN  \n",
       "137068   Twitter for Android                 NaN  \n",
       "180575       Twitter Web App                 NaN  \n",
       "693194       Twitter Web App                 NaN  \n",
       "697397       Twitter Web App                 NaN  \n",
       "1067665  Twitter for Android                 NaN  \n",
       "1347699   Twitter for iPhone                 NaN  \n",
       "1393938   Twitter for iPhone                 NaN  \n",
       "1513850      Twitter Web App                 NaN  \n",
       "1611481   Twitter for iPhone                 NaN  \n",
       "1811149      Twitter Web App                 NaN  \n",
       "2452878                IFTTT                 NaN  \n",
       "2599064  Twitter for Android                 NaN  \n",
       "2612133                False  Isn`t it awesome?   \n",
       "2682674      Twitter Web App                 NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usercreated_errors = pd.to_datetime(df[\"user_created\"], \\\n",
    "                                    errors = 'coerce').isna() #Turns the user_created column into a datetime object \n",
    "                                                              #and turns rows that couldn't be coverted into nulls\n",
    "                                                              #and lastly creates a mask to see rows that have nulls\n",
    "\n",
    "                \n",
    "df.loc[usercreated_errors] #Calls rows that have nulls in them based on the previous mask\n",
    "\n",
    "\n",
    "#It looks like there were input errors all across the data. There are 15 errors in the user_created column. \n",
    "#This is an insignificant amount so we are just going to drop them from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975e175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"user_created\"] = pd.to_datetime(df[\"user_created\"], errors = 'coerce') #Coverts user_created column into a datetime \n",
    "                                                                           #object and makes errors into nulls\n",
    "\n",
    "df.dropna(subset = [\"user_created\"], inplace = True) #Drops all rows with nulls present in the user_created column\n",
    "\n",
    "\n",
    "#We are dropping all rows that couldn't been converted into datetime objects in the user_created column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09e83813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_name                   object\n",
       "user_location               object\n",
       "user_description            object\n",
       "user_created        datetime64[ns]\n",
       "user_followers              object\n",
       "user_friends                object\n",
       "user_favourites             object\n",
       "user_verified               object\n",
       "date                        object\n",
       "text                        object\n",
       "source                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes #Checks to see that datatypes of the dataframe\n",
    "\n",
    "#Verify that the datetype was updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53fa9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"user_followers\"] = df[\"user_followers\"].astype(\"float\") #Converts user_followers into float datatype\n",
    "df[\"user_friends\"] = df[\"user_friends\"].astype(\"float\") #Converts user_friends into float datatype\n",
    "df[\"user_favourites\"] = df[\"user_favourites\"].astype(\"float\") #Converts user_favourites into float dataype\n",
    "df[\"user_verified\"] = df[\"user_verified\"].astype(\"bool\") #Converts user_verified into bool datatype\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "#Convert the rest of the columns to the correct data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60fe649a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_name                   object\n",
       "user_location               object\n",
       "user_description            object\n",
       "user_created        datetime64[ns]\n",
       "user_followers             float64\n",
       "user_friends               float64\n",
       "user_favourites            float64\n",
       "user_verified                 bool\n",
       "date                datetime64[ns]\n",
       "text                        object\n",
       "source                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes #Checks to see that datatypes of the dataframe\n",
    "\n",
    "#Verify that the datetypes were updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae0058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3028948 entries, 0 to 3029117\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   user_name         object        \n",
      " 1   user_location     object        \n",
      " 2   user_description  object        \n",
      " 3   user_created      datetime64[ns]\n",
      " 4   user_followers    float64       \n",
      " 5   user_friends      float64       \n",
      " 6   user_favourites   float64       \n",
      " 7   user_verified     bool          \n",
      " 8   date              datetime64[ns]\n",
      " 9   text              object        \n",
      " 10  source            object        \n",
      "dtypes: bool(1), datetime64[ns](2), float64(3), object(5)\n",
      "memory usage: 257.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() #Checks to see the dataframe info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0b5fa",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this next part we will perform text cleaning and processing. This wil be done so that we can do a better N-Gram \n",
    "#analysis. Our cleaning will involve removing emojis, strange characters, punctuation, stopwords, lemmentizing words, \n",
    "#and converting text to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c3a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a23affb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    text_cleaned = re.sub(r'@[A-Za-z0-9]+','',text) # Removes @\n",
    "    text_cleaned = re.sub(r'#','', text_cleaned) # Removes #\n",
    "    text_cleaned = re.sub(r'RT[\\s]+','',text_cleaned) # Removes RT\n",
    "    text_cleaned = re.sub(r'https?:\\/\\/\\S+','',text_cleaned) # Removes hyperlinks\n",
    "    text_cleaned = text_cleaned.replace('\\n','') # removes \\n\n",
    "    return text_cleaned\n",
    "\n",
    "#We are going to define a function that removes uncessary characters like @, #, RT, /n, and hyperlinks\n",
    "#This is so that we can more easily analyze the contents of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fb1bde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Blue Ridge Bank shares halted by NYSE after bi...\n",
       "1    ðŸ˜Ž Today, that's this Thursday, we will do a \"ðŸŽ¬...\n",
       "2    Guys evening, I have read this article about B...\n",
       "3    $BTC A big chance in a billion! Price: \\487264...\n",
       "4    This network is secured by 9 508 nodes as of t...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_text\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"processed_text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18db1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  \n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "#We will also remove all emojis from the tweets to clean text further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68abbab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Blue Ridge Bank shares halted by NYSE after bi...\n",
       "1     Today, that's this Thursday, we will do a \" T...\n",
       "2    Guys evening, I have read this article about B...\n",
       "3    $BTC A big chance in a billion! Price: \\487264...\n",
       "4    This network is secured by 9 508 nodes as of t...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_text\"] = df[\"processed_text\"].apply(remove_emojis)\n",
    "df[\"processed_text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67fc02b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    blue ridge bank shares halted by nyse after bi...\n",
       "1     today, that's this thursday, we will do a \" t...\n",
       "2    guys evening, i have read this article about b...\n",
       "3    $btc a big chance in a billion! price: \\487264...\n",
       "4    this network is secured by 9 508 nodes as of t...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df['processed_text'].str.lower() #Convert text into lowercase\n",
    "df['processed_text'].head()\n",
    "\n",
    "#This converts all text into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db00bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puncuation(text):\n",
    "    no_punct = [word for word in text if word not in string.punctuation] #Grabs only words without punctuation\n",
    "    words_wo_punct = ''.join(no_punct) #Joins words back together to get full tweet back\n",
    "    return words_wo_punct\n",
    "\n",
    "#This will remove all punctuation from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f158b824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    blue ridge bank shares halted by nyse after bi...\n",
       "1     today thats this thursday we will do a  take ...\n",
       "2    guys evening i have read this article about bt...\n",
       "3    btc a big chance in a billion price 48726440 2...\n",
       "4    this network is secured by 9 508 nodes as of t...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df[\"processed_text\"].apply(remove_puncuation)\n",
    "df['processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4c878a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    blue ridge bank shares halted by nyse after bi...\n",
       "1    today thats this thursday we will do a  take 2...\n",
       "2    guys evening i have read this article about bt...\n",
       "3    btc a big chance in a billion price 48726440 2...\n",
       "4    this network is secured by 9 508 nodes as of t...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_text\"] = df[\"processed_text\"].str.strip() #Removes trailing whitespaces from text\n",
    "df[\"processed_text\"].head()\n",
    "\n",
    "#This will remove all excess whitespace in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07464487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    split = re.split(\"\\W+\", text) #Splits tweet into list format with each word being a value\n",
    "    return split\n",
    "\n",
    "#This will split each word to create a list of words for each tweet. This will allow us to remove stopwords easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8e7ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [blue, ridge, bank, shares, halted, by, nyse, ...\n",
       "1    [today, thats, this, thursday, we, will, do, a...\n",
       "2    [guys, evening, i, have, read, this, article, ...\n",
       "3    [btc, a, big, chance, in, a, billion, price, 4...\n",
       "4    [this, network, is, secured, by, 9, 508, nodes...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df[\"processed_text\"].apply(tokenize)\n",
    "df['processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24793c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopwords] #This will only grab the words that are not stopwords\n",
    "    return text\n",
    "\n",
    "#This will remove stop words from text list. Examples of stopwords are \"the\", \"is\", \"and\". We will remove these\n",
    "#stopwords as they do not provide much value in analyzing text topics as they are only used for grammar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d03fecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [blue, ridge, bank, shares, halted, nyse, bitc...\n",
       "1    [today, thats, thursday, take, 2, friend, btc,...\n",
       "2    [guys, evening, read, article, btc, would, lik...\n",
       "3    [btc, big, chance, billion, price, 48726440, 2...\n",
       "4    [network, secured, 9, 508, nodes, today, soon,...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df['processed_text'].apply(remove_stopwords)\n",
    "df['processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a97ac80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    w = []\n",
    "    for word in text:\n",
    "        w.append(wnet.lemmatize(word)) #This will lemmatize words contained in each tweet\n",
    "    return w\n",
    "\n",
    "#This will lemmatize words allowing the text to be easier to understand. Lemmantizing words means turning different verions\n",
    "#of words such as 'changing', 'changed', 'changes' into the root word 'change'. This will allow us to single out \n",
    "#words as opposed to analzying different words based on the ending of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6907a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [blue, ridge, bank, share, halted, nyse, bitco...\n",
       "1    [today, thats, thursday, take, 2, friend, btc,...\n",
       "2    [guy, evening, read, article, btc, would, like...\n",
       "3    [btc, big, chance, billion, price, 48726440, 2...\n",
       "4    [network, secured, 9, 508, node, today, soon, ...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df['processed_text'].apply(lemmatize_text)\n",
    "df['processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eacd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['processed_text'].apply(lambda x : \" \".join(x)) #This will join each word back together into one\n",
    "                                                                          #string for each tweet. \n",
    "\n",
    "#We will join the text back together into one string "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cda42c",
   "metadata": {},
   "source": [
    "## Text Stats and Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8195db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this part of our processing we will apply different methods to get columns for text statistics and text complexity.\n",
    "#This will be so that we can use these additional columns for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6576c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_reading_ease\n",
    "\n",
    "#Import Necessary Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ce641",
   "metadata": {},
   "source": [
    "## Text Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef1f57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"character_length\"] = df['text'].str.len() #This will grad the length of each tweet in the dataset\n",
    "\n",
    "#Creates a new \"character_length\" column which counts the character length of each tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f43904",
   "metadata": {},
   "source": [
    "## Text Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47c67e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_complexity_score\"] = df['text'].apply(lambda x : flesch_reading_ease(x)) #This will grab a flesh_reading_ease score\n",
    "\n",
    "#Creates a new complexity column which scores the compexity of each tweet with negatives being difficult and postives being\n",
    "#easy to read. The full breakdown of the score is available here https://pypi.org/project/textstat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61152241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data/Bitcoin_tweets_clean.csv\", index = False) #Saves processed dataframe to a csv\n",
    "\n",
    "#After cleaning, text processing, and adding new columns we will save the dataframe into a new csv called \n",
    "#Bitcoin_tweets_clean.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd485d12",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55634f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this part of our processing we are going to create frequency tables for the most occuring N-grams.\n",
    "#An N-gram is a unique sequence of words contained within a document. A monogram is a unique set of words, \n",
    "#a bigram is a set of two unique words, a trigram is a set of three unique words and so forth.\n",
    "\n",
    "#We are going to isolate monograms, bigrams, and trigrams to see what are the most talked about objects in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e91b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e9b34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngrams(text, n=2):\n",
    "    \n",
    "    vec = CountVectorizer(ngram_range = (n,n)).fit(text) #Creates N_grams from text\n",
    "    bag_of_words = vec.transform(text) #Transforms documents to document-term matrix\n",
    "    sum_words = bag_of_words.sum(axis=0) #Sums up the occurances of n_grams\n",
    "    \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()] #Grabs the n_grams and count\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse= True) #Sorts n_gram frequency in descending order\n",
    "    \n",
    "    return words_freq\n",
    "\n",
    "#This function will give a tuple of the n-grams and their count in the dataframe. The n-gram will be produced based on\n",
    "#the number provided when the function is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b90d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "monogram_list = get_top_ngrams(df[\"processed_text\"].astype(\"str\"), 1)[:20] #Calls the top 20 monograms\n",
    "monogram_frequency = pd.DataFrame(monogram_list, columns=[\"n_gram\", \"count\"]) #Creates tuple into a dataframe\n",
    "monogram_frequency.to_csv(\"Data/monogram_frequency.csv\", index = False) #Saves dataframe as a csv\n",
    "\n",
    "#Create monogram frequency table to be used for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae84cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list = get_top_ngrams(df[\"processed_text\"].astype(\"str\"), 2)[:20] #Calls the top 20 bigrams\n",
    "bigram_frequency = pd.DataFrame(bigram_list, columns=[\"n_gram\", \"count\"]) #Creates tuple into a dataframe\n",
    "bigram_frequency.to_csv(\"Data/bigram_frequency.csv\", index = False) #Saves dataframe as a csv\n",
    "\n",
    "#Create bigram frequency table to be used for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19c6c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_list = get_top_ngrams(df[\"processed_text\"].astype(\"str\"), 3)[:20] #Calls the top 20 trigrams\n",
    "trigram_frequency = pd.DataFrame(trigram_list, columns=[\"n_gram\", \"count\"]) #Creates tuple into a dataframe\n",
    "trigram_frequency.to_csv(\"Data/trigram_frequency.csv\", index = False) #Saves dataframe as a csv\n",
    "\n",
    "#Create trigram frequency table to be used for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30086d31",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d28d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this part we are going to create frequency tables for top occuring general named enitties as well as \n",
    "#the top 5 in-depth named entities using Spacy's Named Entity Recognition model.\n",
    "\n",
    "#A named entity is a real world object that's assigned a name such as a person, location, or organization. Spacy's \n",
    "#pre-trained Named Entity Recognition model is able to identify named entites and classify them as either\n",
    "#a person, a geographical location, cardinal, money, and so forth. To learn more about the classifications you\n",
    "#can visit the link here https://spacy.io/usage/linguistic-features\n",
    "\n",
    "#We are going to create named enity frequency tables to identify the most talked about named entities or real-world objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86ee4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from collections import Counter\n",
    "\n",
    "#Import Neccessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73955ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") #Initalize spacy named entity recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2140af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_general(text):\n",
    "    doc=nlp(text) #Initializes our text for spacy to analyze \n",
    "    return [X.label_ for X in doc.ents] #Grabs only the general named entity labels \n",
    "\n",
    "#This function applies spacy's Named entity recognition model onto our text and isolated the general labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09c2aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_general_frequency(df):\n",
    "    \n",
    "    ent = df[\"processed_text\"].apply(lambda x: ner_general(x)) #Calls spacy's named entity recognition model on our text\n",
    "    ent = [x for sub in ent for x in sub] #Isolates the labels from a list of lists to a list of lables\n",
    "    \n",
    "    counter=Counter(ent) #Creates a frequency table of all labels in our text\n",
    "    count=counter.most_common()[:20] #Isolates the top 20 most common labels\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "338e1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_general_list= ner_general_frequency(df) #Calls functions on our text to create frequency table\n",
    "ner_general_df = pd.DataFrame(ner_general_list, columns=[\"NER_General\", \"count\"]) #Creates dataframe out of tuples\n",
    "ner_general_df.to_csv(\"Data/ner_general_df.csv\", index = False) #Saves dataframe as a csv for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8a8d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_in_depth(text,ent=\"CARDINAL\"):\n",
    "    doc=nlp(text) #Applies spacy's model to our text\n",
    "    return [X.text for X in doc.ents if X.label_ == ent] #Isolates the actual named entities we want to analyze\n",
    "\n",
    "#This function applies spacy's Named entity recognition model on our text and isolates the actualy named entities\n",
    "#of a given label that we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fd16390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_in_depth_df(df, in_depth_var):\n",
    "    \n",
    "    ent = df[\"processed_text\"].apply(lambda x: ner_in_depth(x, in_depth_var)) #Calls spacy's named entity recognition \n",
    "                                                                              #model on our text to grab named entities\n",
    "                                                                              #of a given label\n",
    "    \n",
    "    ent = [x for sub in ent for x in sub] #Isolates the named entities from a list of lists to a list of lables \n",
    "    \n",
    "    counter=Counter(ent) #Creates a frequency table of all named entities in our text\n",
    "    count=counter.most_common()[:20] #Isolates the top 20 most common labels\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e607911",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_cardinal_list = ner_in_depth_df(df, \"CARDINAL\") #Calls functions on our text to create frequency table\n",
    "ner_cardinal_df = pd.DataFrame(ner_cardinal_list, columns=[\"NER_Cardinal\", \"count\"]) #Creates dataframe out of tuples\n",
    "ner_cardinal_df.to_csv(\"Data/ner_cardinal_df.csv\", index = False) #Saves dataframe as a csv for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be509764",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_date_list = ner_in_depth_df(df, \"DATE\") #Calls functions on our text to create frequency table\n",
    "ner_date_df = pd.DataFrame(ner_date_list, columns=[\"NER_Date\", \"count\"]) #Creates dataframe out of tuples\n",
    "ner_date_df.to_csv(\"Data/ner_date_df.csv\", index = False) #Saves dataframe as a csv for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfc4af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_org_list = ner_in_depth_df(df, \"ORG\") #Calls functions on our text to create frequency table\n",
    "ner_org_df = pd.DataFrame(ner_org_list, columns=[\"NER_Org\", \"count\"]) #Creates dataframe out of tuples\n",
    "ner_org_df.to_csv(\"Data/ner_org_df.csv\", index = False) #Saves dataframe as a csv for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6017605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_person_list = ner_in_depth_df(df, \"PERSON\") #Calls functions on our text to create frequency table\n",
    "ner_person_df = pd.DataFrame(ner_person_list, columns=[\"NER_Person\", \"count\"]) #Creates dataframe out of tuples\n",
    "ner_person_df.to_csv(\"Data/ner_person_df.csv\", index = False) #Saves dataframe as a csv for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "853816e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_gpe_list = ner_in_depth_df(df, \"GPE\") #Calls functions on our text to create frequency table\n",
    "ner_gpe_df = pd.DataFrame(ner_gpe_list, columns=[\"NER_Gpe\", \"count\"]) #Creates dataframe out of tuples\n",
    "ner_gpe_df.to_csv(\"Data/ner_gpe_df.csv\", index = False) #Saves dataframe as a csv for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that our cleaning and processing is done we can move to the EDA where we will look at the user info data\n",
    "#tweet data, and tweet textual data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
